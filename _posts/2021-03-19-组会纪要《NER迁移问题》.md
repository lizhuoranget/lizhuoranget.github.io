---
layout:     post
title:      组会纪要《NER迁移问题》
subtitle:   
date:       2021-03-19
author:     Zhuoran Li
header-img: 
catalog:    true
tags:
- NER
- 命名实体识别
---


1. group shift problem
2. 文章一的sentence-level的物理意义
3. 上下文、domain adaptive



1. AAAI2020中sentence-level的意义，如何体现全局？

   

2. 无监督fine-tune？

   https://stackoverflow.com/questions/61368630/unsupervised-finetuning-of-bert-for-embeddings-only

   Unsupervised Domain Adaptation of Contextualized Embeddings for Sequence Labeling有介绍

   第一步，对目标域无标签fine tune

   对每个句子使用10个随机的masking，每个masking使用随机15%token进行mask。按照BERT的训练过程，执行了三次迭代。

   如何实现？

   第二步，对源域有标签fine tune

   

3. 模型去掉GRU，加入Majority Vote测试结果

4. 考虑Domain Adaption NER任务

5. 迁移NER问题思路

   * Scientific Concept Extraction     STM-corpus 65.5
* Named Entity Recognition on SciERC     SCIERC 70.33
   * Cross-Domain Named Entity Recognition    CoNLL04 70.04
* Medical Named Entity Recognition    ShARe/CLEF eHealth corpus  79.2
   
   * Semantic Role Labeling    OntoNotes  87、CoNLL 2005 88.5
   * Low Resource Named Entity Recognition    CONLL 2003 German/Spanish /Dutch   65.24/75.93/74.61
   * Entity Typing    Open Entity 78.2、Ontonotes v5 (English) 40.2、
   * Nested Mention Recognition	ACE2005 84.34、ACE2004 85.98
   
   * Domain Labelling	BabelDomains 92.14
   * Joint NER and Classification      BSNLP 50.1
   * Multi-Grained Named Entity Recognition    ACE2005 78.2、ACE2004 79.5、CoNLL 92.28
   
   





Low-resource NER



