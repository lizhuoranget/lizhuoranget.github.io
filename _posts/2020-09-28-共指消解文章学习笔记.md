---
layout:     post
title:      共指消解文章学习笔记
subtitle:   问题理解以及代码阅读
date:       2020-09-28
author:     Zhuoran LI
header-img: img/post-bg-posthk-web.jpg
catalog:    true
tags:
      - 共指消解
---

## 代码实现知识

1. tqdm 

   tqdm是一个快速，**可扩展的Python进度条**，可以在 Python 长循环中添加一个进度提示信息，用户只需要封装任意的迭代器 tqdm(iterator)。

   https://blog.csdn.net/qq_33472765/article/details/82940843

2. *args和**kwargs

   这两个是python中的可变参数。*args表示任何多个无名参数，它是一个tuple；**kwargs表示关键字参数，它是一个dict。

   https://www.cnblogs.com/fengmk2/archive/2008/04/21/1163766.html

3. combinations

   Python的itertools库中提供了`combinations`方法可以轻松的实现排列组合。

   https://blog.csdn.net/cloume/article/details/76399093

4. torch.nn.functional.normalize

   本质上就是按照某个维度计算范数，p表示计算p范数（等于2就是2范数），dim计算范数的维度（这里为1，一般就是通道数那个维度）

   https://blog.csdn.net/u013066730/article/details/95208287

5. torch.nn.Embedding

   在pytorch里面实现`word embedding`是通过一个函数来实现的:`nn.Embedding`，只需要调用 torch.nn.Embedding(m, n) 就可以了，m 表示单词的总数目，n 表示词嵌入的维度

   https://www.cnblogs.com/lindaxin/p/7991436.html

   如果从使用已经训练好的词向量，则采用

   ```python
   # GLoVE
   self.glove = nn.Embedding(glove_weights.shape[0], glove_weights.shape[1])
   self.glove.weight.data.copy_(glove_weights)
   ```

   https://blog.csdn.net/david0611/article/details/81090371

6. torch.nn.Conv1d

   https://blog.csdn.net/sunny_xsc1994/article/details/82969867

   torch.nn.Conv1d 与 torch.nn.Conv2d

   https://www.jianshu.com/p/45a26d278473



## 代码结构

coref.py, loader.py, utils.py

<center class="half">
	<img src="../images/20200928coref/coref.png" width=30% alt>
	<img src="../images/20200928coref/loader.png" width=30% alt>
	<img src="../images/20200928coref/utils.png" width=30% alt>
</center>

### coref.py

类：
