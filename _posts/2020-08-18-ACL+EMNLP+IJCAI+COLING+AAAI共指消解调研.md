---
layout:     post
title:      ACL+EMNLP+IJCAI+COLING+AAAI共指消解调研
subtitle:   
date:       2020-08-18
author:     lizhuoran
header-img: img/post-bg-acl.jpg
catalog: true
tags:
- 指代消解
---
## 1 Incorporating Structural Information for Better Coreference Resolution（2019,IJCAI）

指代消解在自然语言处理中发挥重要的作用。但是之前的研究大多都忽略了结构信息的作用。本文主要从三个方面研究如何将结构信息有效地融入神经共指消解中。首先，利用解析树中的节点作为约束条件，过滤出不可能的文本实体（即候选实体），以降低计算复杂度。其次，将上下文信息编码在遍历节点序列中而不是字序列中，以更好地捕捉文本跨度表示的层次信息。最后，对附加的结构特征（如路径、同级、度、当前节点的类别）进行编码，以增强实体表示。实验展示了在CoNLL 2012上的有效性。

## 2 BERT for Coreference Resolution: Baselines and Analysis（2019,EMNLP）

我们将BERT应用于共指消解，在OntoNotes（+3.9 F1）和GAP（+11.5 F1）基准上实现了强大的改进。模型预测的定性分析表明，与ELMo和BERT-base相比，BERT-large在区分相关但不同的实体（如President和CEO）方面尤其出色。然而，在建模文档级上下文、对话和提及释义方面仍有改进的余地。我们的代码和模型是公开的。

## 3 Revisiting Joint Modeling of Cross-document Entity and Event Coreference Resolution（2019,ACL）

本文与大多数文档内部的共指消解不同，提出一个跨文档的共指消解神经架构。受[Lee(2012)](https://www.aclweb.org/anthology/D12-1045.pdf)启发，我们联合建模实体和事件共指。我们使用事件（实体）的词汇量、周围的上下文以及通过谓词参数结构与实体（事件）提及的关系来表示事件（实体）。我们的模型在ECB+上优于先前最先进的事件共指模型，同时在该语料库上提供了第一个实体共指结果。我们的分析 证实了我们所有的表示元素，包括实体本身，它的上下文，以及与其他实体关系都有助于模型的成功。

## 4 Knowledge-aware Pronoun Coreference Resolution（2019,ACL）

解决共指消解需要知识支持，尤其是在特殊领域。这篇论文探索了如何利用不同的知识解决共指消解问题。为了保证模型的泛化能力，我们直接将知识以三元组的形式合并，这是现代知识图中最常见的格式，而不是像传统方法那样用特征或规则编码。此外，由于并非所有的知识在特定的语境中都有帮助，为了有选择地使用它们，我们提出了一个知识注意模块，该模块学习根据上下文选择和使用信息性知识，以增强我们的模型。在两个来自不同领域的数据集上的实验结果证明了我们的模型的有效性和有效性，它在很大程度上优于最先进的基线。此外，由于我们的模型学习使用外部知识而不仅仅是拟合训练数据，因此它在跨域设置中也表现出优于基线的性能。

## 5 End-to-end Deep Reinforcement Learning Based Coreference Resolution（2019,ACL）

然而，目前的神经共指模型通常使用启发式损失函数进行训练，这些损失函数是在一系列局部决策的基础上计算出来的。本文提出了一种基于端到端强化学习的共指消解模型，直接优化共指评价指标。具体来说，我们修改了 [Lee（2018年）](https://www.aclweb.org/anthology/N18-2108.pdf)等人提出的最新的高阶实体排序方法。通过合并与一系列同指关联行动相关的奖励来强化政策梯度模型。

## 6 Coreference Resolution with Entity Equalization（2019,ACL）

共指消解的一个关键挑战是获取实体簇的属性，并在解析过程中使用这些属性。在这里，我们提供了一个简单有效的方法来实现这一点，通过一个“实体均衡”机制。均衡方法通过簇中所有提及的和的近似值来表示簇中的每个实体。我们展示了如何以完全可微的端到端方式完成这一点，从而在解析过程中实现高阶推断。我们的方法也使用了BERT嵌入，在CoNLL-2012共指消解任务中产生了最新的结果，平均F1提高了3.6%。

## 7 Event Coreference Resolution: A Survey of Two Decades of Research（2018,IJCAI）

近年来，信息抽取研究的重点逐渐从基于实体的任务转移到基于事件的任务。作为一项基于事件的核心任务，事件共指消解研究较少，但可以说比实体共指消解更具挑战性。本文概述了事件共指研究自二十年前创立以来取得的主要里程碑。

## 8 PreCo: A Large-scale Dataset in Preschool Vocabulary for Coreference Resolution（EMNLP,2018）

我们介绍了PreCo，一个用于共指消解的大规模英语数据集。该数据集旨在通过减轻训练集和测试集之间低重叠的挑战，实现提述检测和提述聚类的分离分析，体现共指中的核心挑战，如实体表示。为了加强训练测试的重叠，我们收集了大量的38K个文档和1250万个单词的语料库，这些词汇大部分来自讲英语的学龄前儿童的词汇。实验结果表明，在训练测试重叠度较高的情况下，PreCo的误差分析比现有的Ontobotes数据集更有效。此外，我们还对单例实体进行了注释，使得首次量化实体检测器对共指消解性能的影响成为可能。[数据集地址](https://preschool-lab.github.io/PreCo/)。

## 9 Triad-based Neural Network for Coreference Resolution（COLING,2018）

我们提出了一个基于三元组的神经网络系统来产生实体间的亲和力得分，以进行共指消解。该系统同时接受三个实体作为输入，考虑了三个实体的相互依赖性和逻辑约束，从而比传统的成对预测方法更准确。根据系统选择，亲和力得分可以进一步用于聚类或提及排名。我们的实验表明，在CoNLL 2012共享任务的英语部分，使用分数的标准分层聚类产生了MUC和$B^3​$​指标的最新结果。该模型不依赖于许多手工特征，并且易于训练和使用。三元组也可以很容易地推广到更高阶的多元体。据我们所知，这是第一个神经网络系统模型的相互依赖超过两个实体成员。

## 10 *They* Exist! Introducing Plural Mentions to Coreference Resolution and Entity Linking（COLING,2018）

本文分析了，如共指消解和实体链接等消解任务中最具挑战性的方面，即复数实体的消解。不同于单数实体，每个代表一个实体，复数实体代表多个实体。为了解决这一问题，我们从SemEval 2018共享任务中获取字符识别语料库，该任务包含单数提到的实体注释，并通过添加复数实体的注释来扩展它。然后介绍了一种新的共指消解算法，该算法选择性地创建集群来处理单数和复数实体，以及一个基于深度学习的实体链接模型，该模型通过多任务学习联合处理两种类型的实体。针对这些任务提出了调整后的评价指标，以处理复数实体的唯一性。我们的实验表明，新的共指消解和实体链接模型明显优于仅针对单数实体设计的传统模型。据我们所知，这是第一次对这两个解析任务的复数实体进行彻底分析。

## 11 Graph-Based Decoding for Event Coreference and Sequencing Resolution（COLING,2018）

文本中提及的事件之间常存在着复杂的关系。在这篇文章中，我们主要研究两种关系：事件间的共指关系以及依序关系。我们指出，常被应用在事件指代消歧上的传统的树结构解码方式并不适用于解决事件依序问题。为了解决这个问题，我们提出了一种适用于两种情况的新的图结构解码算法。这个算法让我们可以为这两个任务设计灵活的特征。在实验上，我们的事件共指消解系统在TAC-KBP 2015的共指消解任务上达到了目前最佳的水平。同时，我们的依序关系系统的结果超过了一个基于时间分析并有部分正确答案的基线系统。最后我们分析了结果，并讨论了事件关系判别任务的一些挑战。

## 12 Neural Cross-Lingual Coreference Resolution And Its Application To Entity Linking（ACL,2018）

我们提出了一个基于多语言嵌入和语言无关特征的以实体为中心的神经跨语言共指模型。我们对模型进行内部和外部评估。在内在评价中，我们发现我们的模型在接受英语训练和汉语和西班牙语测试时，分别取得了与直接用汉语和西班牙语训练的模型相比较的结果。在外部评估中，我们表明，我们的英语模型有助于在中文和西班牙语测试集上实现优于2015年顶级TAC系统的实体链接精度，而不使用任何来自中文或西班牙语的注释数据。

## 13 Neural Coreference Resolution with Deep Biaffine Attention by Joint Mention Detection and Mention Clustering（ACL,2018）

共指消解的目的是在一篇文章中找出所有提及到同一个真实世界实体的内容。最先进的端到端神经共指模型将文档中的所有文本跨度视为潜在的实体，并学习为每个可能的实体链接一个先行词。本文提出了一种改进的端到端共指消解系统，其方法是：（1）使用双仿射注意模型对每一个可能的实体进行先行词评分；（2）在给定实体聚类标签的情况下，联合优化实体检测精度和实体聚类日志似然度。我们的模型在CONLL-2012共享任务英语测试集上达到了最先进的性能。

## 14 Improving Event Coreference Resolution by Modeling Correlations between Event Coreference Chains and Document Topic Structures（ACL,2018）

本文提出了一种新的事件共指消解方法，该方法通过整数线性规划来模拟事件共指链与文档主题结构之间的关联。我们用主题转换句、指代间链关联、事件-实体分布特征和子事件结构对文档主事件链之间的关联进行了显式建模，用一个事件链和一个局部共指关系得到的一个分类器和一个局部共指关系。我们对KBP 2016和2017数据集的实验表明，每种结构都有助于提高事件共指消解性能。

## 15 Entity-Centric Joint Modeling of Japanese Coreference Resolution and Predicate Argument Structure Analysis（ACL,2018）

谓元结构分析是识别结构化事件的一项任务。为了改善这一领域，我们需要识别出一个显著的实体，如果不同时进行共指消解和谓词-论元结构分析，就无法识别出显著实体。本文提出了一个以实体为中心的日语共指消解和谓词-论元结构分析的联合模型。每个实体都被分配了一个嵌入，当两个分析的结果都指向一个实体时，将更新实体嵌入。分析中考虑了实体嵌入，以获取实体的全局信息。实验结果表明，该方法能显著提高句子间零回指消解的性能，这是谓词-论元结构分析中的一个难点。

## 16 Revisiting Selectional Preferences for Coreference Resolution（EMNLP,2017）

长期以来，选择偏好一直被认为对共指消解至关重要。然而，它们主要是由当前的共指解析器隐式地建模的。我们提出了一个基于依赖关系的选择偏好嵌入模型，该模型允许高覆盖率的细粒度兼容性判断。我们表明，我们的模型的合并提高了CoNLL数据集的共指解析性能，与更复杂系统的最新结果相匹配。然而，它所带来的代价，让人对这样的改进有多值得商榷。

## 17 Event Coreference Resolution by Iteratively Unfolding Inter-dependencies among Events（EMNLP,2017）

我们介绍了一种新的事件共指解析迭代方法，该方法通过利用同一链中事件实体之间以及事件链之间的相互依赖性逐步构建事件集群。在同一链中的事件实体中，我们使用两个不同的成对分类器来区分文档内和跨文档的事件共指链接，分别训练这些分类器来捕获文档内和跨文档事件簇的特征分布差异。我们的事件共指方法在WD和CD集群之间交替使用，并在每次合并之后合并来自两个事件集群的参数，直到无法进行更多的合并。然后它在事件链之间执行进一步的合并，这些事件链都与一组其他事件链密切相关。在ECB+语料库上的实验表明，该模型在WD和CD事件共指消解的联合任务中优于现有的方法。

## 18 End-to-end Neural Coreference Resolution（EMNLP,2017）

## 19 Lexical Features in Coreference Resolution: To be Used With Caution（ACL,2017）

词汇特征是最先进的共指消解器中信息的主要来源。词汇特征在精细的层次上隐含地模拟了一些语言现象。它们对于表示实体的上下文特别有用。在本文中，我们研究了在最先进的共指消解器中使用许多词汇特征的缺点。我们发现，如果共指消解器主要依赖词汇特征，那么它们很难推广到不可见的领域。此外，我们还指出，目前的共指分辨率评估方法存在明显的缺陷，即只评估特定数据集的特定部分，其中训练集、开发集和测试集之间存在显著重叠。

## 20 Joint Learning for Event Coreference Resolution（ACL,2017）

虽然已经为许多NLP任务开发了联合模型，但绝大多数事件共指解析器（包括最近在TAC KBP 2016事件块检测和共指任务中竞争的性能最好的解析器）都是基于管道的，其中，错误从触发器检测组件传播到事件共指组件是一个主要的性能限制因素。为了解决这个问题，我们提出了一个联合学习事件共指、触发检测和事件回指的模型。我们的联合模型在任务选择和捕获跨任务交互的特性方面是新颖的。据我们所知，这是第一次尝试训练一个提及排名模型和使用事件回指来进行事件共指。我们的模型在KBP 2016中英文数据集上取得了迄今为止最好的结果。

## 21 Don’t understand a measure? Learn it: Structured Prediction for Coreference Resolution optimizing its measures（ACL,2017）

结构化预测的一个重要方面是根据标准评估产出结构。特别是在损耗增大的情况下，寻找最大违反约束的需求严重限制了有效损失函数的表达。在本文中，我们在精确计算的基础上，考虑到使用更复杂的损失函数进行共指分辨率（CR）。最值得注意的是，我们展示了这些函数可以（i）自动地从有争议但普遍接受的CR度量中学习，例如MELA，和（ii）成功地用于学习算法。在标准CoNLL–2012设置下进行的精确模型比较表明，阿拉伯语和英语数据更具表现力。

## 22 Machine Learning for Entity Coreference Resolution: A Retrospective Look at Two Decades of Research（AAAI,2017）

自20世纪60年代以来，实体共指消解作为自然语言理解的核心任务，至今仍未得到解决。然而，自二十年前兴起以来，基于学习的共指研究取得了重大进展。本文概述了基于学习的共指研究的主要里程碑，并讨论了最近在人工智能界备受关注的硬实体共指任务Winograd Schema Challenge。

## 23 Active Learning for Coreference Resolution using Discrete Annotation（ACL,2020）

在共指消解中，我们改进了成对注释，通过让注释者在被认为不是同指物的情况下识别实体先行词。这个简单的修改，当结合一个新的实体聚类算法来选择要标记的例子时，就每个注释预算获得的性能而言，效率要高得多。在对现有基准共指数据集的实验中，我们表明，来自这个附加问题的信号可以显著提高每小时人工注释的性能。未来的工作可以使用我们的注释协议来有效地为新的领域开发共指模型。我们的代码是[公开的](https://github.com/belindal/discrete-active-learning-coref)。

## 24 CorefQA: Coreference Resolution as Query-based Span Prediction（ACL,2020）

在这篇文章中，我们提出了CorefQA，一个精确且可扩展的共指解析任务方法。我们将问题描述为一个跨度预测任务，类似于问答：使用其周围的上下文为每个候选实体生成一个查询，并使用跨度预测模块提取文档中使用生成的查询的共指文本跨度。该公式具有以下主要优点：（1）广度预测策略提供了检索实体建议阶段遗漏的实体的灵活性；（2）在问答框架中，在查询中显式地对实体及其上下文进行编码，可以对嵌入在相关实体上下文中的线索进行深入而彻底的检查；（3）可以使用大量现有的问答数据集进行数据扩充，以提高模型的泛化能力。

## 25 Toward Gender-Inclusive Coreference Resolution（ACL,2020）

正确地解决文本中提到的人，从根本上说需要对这些人进行推论。这种推断增加了共指消解系统中系统偏差的风险，包括可能损害二元或非二元跨利益相关者和独联体利益相关者。为了更好地理解这些偏见，我们展望了社会学和社会语言学对性别概念的细微差别，并开发了两个新的数据集，用以询问人群注释和现有的共指消解系统中的偏见。通过对英语文本进行的这些研究，我们确认，在不承认和建立承认性别复杂性的系统的情况下，我们建立的系统会导致许多潜在的危害。